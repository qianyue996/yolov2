{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import VOCDetection\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "from dataset import YoloVOCDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=416\n",
    "\n",
    "voc_ds=VOCDetection(root='data',year='2012',image_set='train',download=False)\n",
    "classdict=set()\n",
    "anchor_boxex=[]\n",
    "for _,label in tqdm(voc_ds, desc=\"数据集处理中\"):\n",
    "    for obj in label['annotation']['object']:\n",
    "        classdict.add(obj['name'])\n",
    "        xmin,ymin=int(obj['bndbox']['xmin']),int(obj['bndbox']['ymin'])\n",
    "        xmax,ymax=int(obj['bndbox']['xmax']),int(obj['bndbox']['ymax'])\n",
    "        w=xmax-xmin\n",
    "        h=ymax-ymin\n",
    "        anchor_boxex.append([w,h])\n",
    "names=sorted(list(classdict))\n",
    "id2name={i:c for i,c in enumerate(names)}\n",
    "name2id={c:i for i,c in id2name.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
